# -*- coding: utf-8 -*-
"""Copy of SketchtoImage pix2pix.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AIAA15lIIx1bf0RaLYoc6u64TETbcH9a
"""

# ============================================================
# 1. Setup Kaggle API credentials
# ============================================================
from google.colab import files
import os

print("üìÅ Please upload your kaggle.json file (from https://www.kaggle.com > Account > Create API Token)")
files.upload()

# Move kaggle.json to correct location
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

# Test Kaggle setup
!kaggle datasets list | head -n 5


# ============================================================
# 2. Download dataset from Kaggle
# ============================================================
!kaggle datasets download -d almightyj/person-face-sketches


# ============================================================
# 3. Extract the dataset
# ============================================================
import zipfile

zip_path = "person-face-sketches.zip"
extract_dir = "/content/dataset"

if not os.path.exists(extract_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)

print("‚úÖ Dataset extracted to:", extract_dir)
print("üìÇ Subfolders:", os.listdir(extract_dir))


# ============================================================
# 4. Inspect dataset structure
# ============================================================
import glob

for split in ['train', 'test', 'val']:
    photo_dir = os.path.join(extract_dir, split, 'photos')
    sketch_dir = os.path.join(extract_dir, split, 'sketches')

    num_photos = len(glob.glob(os.path.join(photo_dir, '*')))
    num_sketches = len(glob.glob(os.path.join(sketch_dir, '*')))

    print(f"\nüìÅ {split.upper()} SET:")
    print(f"  Photos: {num_photos}")
    print(f"  Sketches: {num_sketches}")

print("\n‚úÖ Dataset ready for use!")

# ============================================================
# 5. Dataset & DataLoader
# ============================================================
from torchvision import transforms, datasets
from torch.utils.data import Dataset, DataLoader
from PIL import Image

class SketchPhotoDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.sketch_dir = os.path.join(root_dir, 'sketches')
        self.photo_dir = os.path.join(root_dir, 'photos')
        self.transform = transform
        self.sketches = sorted(os.listdir(self.sketch_dir))
        self.photos = sorted(os.listdir(self.photo_dir))

    def __len__(self):
        return len(self.sketches)

    def __getitem__(self, idx):
        sketch_path = os.path.join(self.sketch_dir, self.sketches[idx])
        photo_path = os.path.join(self.photo_dir, self.photos[idx])

        sketch = Image.open(sketch_path).convert("L")   # grayscale
        photo = Image.open(photo_path).convert("RGB")   # color

        if self.transform:
            sketch = self.transform(sketch)
            photo = self.transform(photo)

        return sketch, photo


transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

train_dataset = SketchPhotoDataset(os.path.join(extract_dir, 'train'), transform=transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

print(f"‚úÖ Train samples: {len(train_dataset)}")

# ============================================================
# Fixed UNetGenerator
# ============================================================
import torch.nn as nn
import torch

class UNetGenerator(nn.Module):
    def __init__(self, in_ch=1, out_ch=3):
        super().__init__()
        # Encoder
        self.down1 = self.contract(in_ch, 64, norm=False)   # 1 ‚Üí 64
        self.down2 = self.contract(64, 128)                 # 64 ‚Üí 128
        self.down3 = self.contract(128, 256)                # 128 ‚Üí 256
        self.down4 = self.contract(256, 512)                # 256 ‚Üí 512
        self.down5 = self.contract(512, 512)                # 512 ‚Üí 512
        self.down6 = self.contract(512, 512)                # 512 ‚Üí 512

        # Decoder (reverse order)
        self.up1 = self.expand(512, 512, dropout=True)      # 512 ‚Üí 512
        self.up2 = self.expand(1024, 512, dropout=True)     # (512+512) ‚Üí 512
        self.up3 = self.expand(1024, 256)                   # (512+512) ‚Üí 256
        self.up4 = self.expand(512, 128)                    # (256+256) ‚Üí 128
        self.final_up = self.expand(256, 64)                # (128+128) ‚Üí 64

        # Final output layer
        self.final = nn.Sequential(
            nn.ConvTranspose2d(128, out_ch, 4, 2, 1),
            nn.Tanh()
        )

    def contract(self, in_c, out_c, norm=True):
        layers = [nn.Conv2d(in_c, out_c, 4, 2, 1, bias=False)]
        if norm:
            layers.append(nn.BatchNorm2d(out_c))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        return nn.Sequential(*layers)

    def expand(self, in_c, out_c, dropout=False):
        layers = [
            nn.ConvTranspose2d(in_c, out_c, 4, 2, 1, bias=False),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True)
        ]
        if dropout:
            layers.append(nn.Dropout(0.5))
        return nn.Sequential(*layers)

    def forward(self, x):
        # Downsampling
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)
        d5 = self.down5(d4)
        d6 = self.down6(d5)

        # Upsampling + skip connections
        u1 = self.up1(d6)
        u2 = self.up2(torch.cat([u1, d5], 1))
        u3 = self.up3(torch.cat([u2, d4], 1))
        u4 = self.up4(torch.cat([u3, d3], 1))
        u5 = self.final_up(torch.cat([u4, d2], 1))
        out = self.final(torch.cat([u5, d1], 1))
        return out

# ============================================================
# 7. Training Setup
# ============================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

G = UNetGenerator().to(device)
D = PatchDiscriminator().to(device)

criterion_GAN = nn.BCELoss()
criterion_L1 = nn.L1Loss()

optimizer_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))

# ============================================================
# 6. PatchGAN Discriminator
# ============================================================
import torch.nn as nn
import torch

class PatchDiscriminator(nn.Module):
    def __init__(self, in_ch=4):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_ch, 64, 4, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 1, 4, 1, 1),
            nn.Sigmoid()
        )

    def forward(self, x, y):
        xy = torch.cat([x, y], dim=1)
        return self.model(xy)

from google.colab import drive
drive.mount('/content/drive')

SAVE_DIR = "/content/drive/MyDrive/Colab Notebooks"
import os
os.makedirs(SAVE_DIR, exist_ok=True)
print("Saving to:", SAVE_DIR)

# ============================================================
# 1. Setup
# ============================================================
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import os
from torchmetrics.functional import peak_signal_noise_ratio as psnr
from torchmetrics.functional import structural_similarity_index_measure as ssim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("‚úÖ Using device:", device)

# Save folder in Drive
SAVE_DIR = "/content/drive/MyDrive/pix2pix_fast_checkpoints"
os.makedirs(SAVE_DIR, exist_ok=True)
print("üìÅ Save directory:", SAVE_DIR)


# ============================================================
# 2. UNet Generator
# ============================================================
class UNetGenerator(nn.Module):
    def __init__(self, in_ch=1, out_ch=3):
        super().__init__()

        self.down1 = self.contract(in_ch, 64, norm=False)
        self.down2 = self.contract(64, 128)
        self.down3 = self.contract(128, 256)
        self.down4 = self.contract(256, 512)
        self.down5 = self.contract(512, 512)
        self.down6 = self.contract(512, 512)

        self.up1 = self.expand(512, 512, dropout=True)
        self.up2 = self.expand(1024, 512, dropout=True)
        self.up3 = self.expand(1024, 256)
        self.up4 = self.expand(512, 128)
        self.up5 = self.expand(256, 64)

        self.final = nn.Sequential(
            nn.ConvTranspose2d(128, out_ch, 4, 2, 1),
            nn.Tanh()
        )

    def contract(self, in_c, out_c, norm=True):
        layers = [nn.Conv2d(in_c, out_c, 4, 2, 1)]
        if norm:
            layers.append(nn.BatchNorm2d(out_c))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        return nn.Sequential(*layers)

    def expand(self, in_c, out_c, dropout=False):
        layers = [
            nn.ConvTranspose2d(in_c, out_c, 4, 2, 1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True)
        ]
        if dropout:
            layers.append(nn.Dropout(0.5))
        return nn.Sequential(*layers)

    def forward(self, x):
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)
        d5 = self.down5(d4)
        d6 = self.down6(d5)

        u1 = self.up1(d6)
        u2 = self.up2(torch.cat([u1, d5], 1))
        u3 = self.up3(torch.cat([u2, d4], 1))
        u4 = self.up4(torch.cat([u3, d3], 1))
        u5 = self.up5(torch.cat([u4, d2], 1))

        return self.final(torch.cat([u5, d1], 1))


# ============================================================
# 3. PatchGAN Discriminator
# ============================================================
class PatchDiscriminator(nn.Module):
    def __init__(self, in_ch=4):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_ch, 64, 4, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 1, 4, 1, 1),
            nn.Sigmoid()
        )

    def forward(self, x, y):
        return self.model(torch.cat([x, y], dim=1))


# ============================================================
# 4. Initialize Models + Optimizers
# ============================================================
G = UNetGenerator().to(device)
D = PatchDiscriminator().to(device)

criterion_GAN = nn.BCELoss()
criterion_L1 = nn.L1Loss()

optimizer_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))


# ============================================================
# 5. Dataset (limit to 647 samples)
# ============================================================
subset_size = 647
train_subset, _ = random_split(train_dataset, [subset_size, len(train_dataset) - subset_size])
train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)

print(f"üìå Training samples: {len(train_subset)}")


# ============================================================
# 6. FAST Training Loop (FIXED LABEL SHAPES)
# ============================================================
epochs = 100

for epoch in range(epochs):
    G.train()
    D.train()

    total_D = total_G = total_psnr = total_ssim = 0

    for sketch, photo in tqdm(train_loader):

        sketch, photo = sketch.to(device), photo.to(device)

        # ---- Train D ----
        optimizer_D.zero_grad()

        real_out = D(sketch, photo)
        fake_img = G(sketch)
        fake_out = D(sketch, fake_img.detach())

        # FIXED ‚Äî label size matches discriminator output
        real_label = torch.ones_like(real_out)
        fake_label = torch.zeros_like(fake_out)

        d_loss = (criterion_GAN(real_out, real_label) +
                  criterion_GAN(fake_out, fake_label)) * 0.5

        d_loss.backward()
        optimizer_D.step()

        # ---- Train G ----
        optimizer_G.zero_grad()

        fake_out = D(sketch, fake_img)
        real_label = torch.ones_like(fake_out)  # match size again

        g_gan_loss = criterion_GAN(fake_out, real_label)
        g_l1_loss = criterion_L1(fake_img, photo) * 100

        g_loss = g_gan_loss + g_l1_loss
        g_loss.backward()
        optimizer_G.step()

        total_D += d_loss.item()
        total_G += g_loss.item()
        total_psnr += psnr(fake_img, photo).item()
        total_ssim += ssim(fake_img, photo).item()

    print(f"\nEpoch [{epoch+1}/{epochs}] "
          f"| D Loss: {total_D/len(train_loader):.4f} "
          f"| G Loss: {total_G/len(train_loader):.4f} "
          f"| PSNR: {total_psnr/len(train_loader):.4f} "
          f"| SSIM: {total_ssim/len(train_loader):.4f}")

    torch.save(G.state_dict(), f"{SAVE_DIR}/G_epoch{epoch+1}.pth")
    torch.save(D.state_dict(), f"{SAVE_DIR}/D_epoch{epoch+1}.pth")
    print(f"üíæ Saved models ‚Üí epoch {epoch+1}")

from google.colab import drive
drive.mount('/content/drive')

!pip install torchmetrics

# ============================================================
# 7. Show results after training
# ============================================================
def show_results(model, data_loader, device, num_examples=5):
    model.eval()
    with torch.no_grad():
        sketch, photo = next(iter(data_loader))
        sketch, photo = sketch.to(device), photo.to(device)
        generated = model(sketch).cpu()

    sketch, photo = sketch.cpu(), photo.cpu()
    plt.figure(figsize=(12, 6))
    for i in range(num_examples):
        plt.subplot(3, num_examples, i + 1)
        plt.imshow(sketch[i].squeeze(), cmap="gray")
        plt.title("Sketch")
        plt.axis("off")

        plt.subplot(3, num_examples, i + 1 + num_examples)
        plt.imshow(photo[i].permute(1, 2, 0))
        plt.title("Real")
        plt.axis("off")

        plt.subplot(3, num_examples, i + 1 + 2 * num_examples)
        plt.imshow(generated[i].permute(1, 2, 0))
        plt.title("Generated")
        plt.axis("off")

    plt.tight_layout()
    plt.show()


# Show example results
show_results(G, train_loader, device, num_examples=5)