# -*- coding: utf-8 -*-
"""VAE_ForensicSketchToRealisticImage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G_cWXqPqch4I7Z_GsOLOYyYQpwsgNRuZ

Install packages
"""

# Run in a Colab cell
!pip install -q torch torchvision torchaudio
!pip install -q pillow matplotlib scikit-image tqdm lpips pytorch-fid
!pip install -q git+https://github.com/openai/CLIP.git

"""Imports & device"""

import os, json, math, random, subprocess, shutil
from glob import glob
from PIL import Image
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
import torchvision.utils as vutils

from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr

# Optional: LPIPS and CLIP (if installed); handle gracefully if missing
try:
    import lpips
    LPIPS_AVAILABLE = True
    lpips_alex = lpips.LPIPS(net='alex').to('cuda' if torch.cuda.is_available() else 'cpu')
except Exception as e:
    LPIPS_AVAILABLE = False
    print("LPIPS not available:", e)

try:
    import clip
    CLIP_AVAILABLE = True
    clip_model, clip_preprocess = clip.load("ViT-B/32", device='cuda' if torch.cuda.is_available() else 'cpu')
except Exception as e:
    CLIP_AVAILABLE = False
    print("CLIP not available:", e)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)



"""Mount Drive and set dataset/checkpoint paths"""

from google.colab import drive
import zipfile

drive.mount('/content/drive')

ZIP_FILE_PATH = "/content/drive/MyDrive/sketch2real_dataset.zip"
EXTRACT_PATH = "/content/sketch2real_data_extracted"
os.makedirs(EXTRACT_PATH, exist_ok=True)

print("Unzipping dataset...")
with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:
    zip_ref.extractall(EXTRACT_PATH)
print("‚úÖ Unzip Done")

# ‚úÖ Correct dataset root
DATA_ROOT = EXTRACT_PATH  # it contains train/ , val/ , test/

DRIVE_SAVE_DIR = "/content/drive/MyDrive/vae_sketch2real_checkpoints"
os.makedirs(DRIVE_SAVE_DIR, exist_ok=True)

print("‚úÖ DATA_ROOT =", DATA_ROOT)
print("‚úÖ SAVE_DIR =", DRIVE_SAVE_DIR)

"""Dataset Loader"""

class PairedImageDataset(Dataset):
    def __init__(self, root_dir, split='train', transform=None,
                 input_subfolder='sketches', target_subfolder='photos'):

        self.input_dir = os.path.join(root_dir, split, input_subfolder)
        self.target_dir = os.path.join(root_dir, split, target_subfolder)

        self.transform = transform
        self.input_paths = sorted(glob(os.path.join(self.input_dir, "*")))

        self.pairs = []
        for p in self.input_paths:
            name = os.path.basename(p)
            t = os.path.join(self.target_dir, name)
            if os.path.exists(t):
                self.pairs.append((p, t))

        if len(self.pairs) == 0:
            raise RuntimeError(f"No paired images found in:\n{self.input_dir}\n{self.target_dir}")

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        inp, tar = self.pairs[idx]
        sketch = Image.open(inp).convert("RGB")
        real = Image.open(tar).convert("RGB")

        if self.transform:
            sketch = self.transform(sketch)
            real = self.transform(real)

        return sketch, real, os.path.basename(inp)

"""Transforms + Data Loaders"""

IMG_SIZE = 128
BATCH_SIZE = 16

transform = T.Compose([
    T.Resize((IMG_SIZE, IMG_SIZE)),
    T.ToTensor(),
    T.Normalize([0.5]*3, [0.5]*3)
])

train_ds = PairedImageDataset(DATA_ROOT, "train", transform)
val_ds   = PairedImageDataset(DATA_ROOT, "val", transform)
test_ds  = PairedImageDataset(DATA_ROOT, "test", transform)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

print("‚úÖ Train:", len(train_ds),
      " Val:", len(val_ds),
      " Test:", len(test_ds))

"""VAE Model"""

import torch
import torch.nn as nn

# ==============================
#   ENCODER
# ==============================
class Encoder(nn.Module):
    def __init__(self, in_channels=3, img_size=128, latent_dim=256):
        super().__init__()
        self.img_size = img_size

        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, 64, 4, 2, 1),   # 64 √ó 64 √ó 64
            nn.ReLU(True),

            nn.Conv2d(64, 128, 4, 2, 1),           # 128 √ó 32 √ó 32
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.Conv2d(128, 256, 4, 2, 1),          # 256 √ó 16 √ó 16
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.Conv2d(256, 512, 4, 2, 1),          # 512 √ó 8 √ó 8
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.Flatten()
        )

        self.flatten_dim = 512 * (img_size // 16) * (img_size // 16)

        self.fc_mu = nn.Linear(self.flatten_dim, latent_dim)
        self.fc_logvar = nn.Linear(self.flatten_dim, latent_dim)

    def forward(self, x):
        h = self.conv(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar


# ==============================
#   DECODER
# ==============================
class Decoder(nn.Module):
    def __init__(self, out_channels=3, img_size=128, latent_dim=256):
        super().__init__()
        self.img_size = img_size

        self.initial_dim = (img_size // 16)
        self.fc = nn.Linear(latent_dim, 512 * self.initial_dim * self.initial_dim)

        self.net = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, 2, 1),  # 256 √ó 16 √ó 16
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 128 √ó 32 √ó 32
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 64 √ó 64 √ó 64
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, out_channels, 4, 2, 1),  # 3 √ó 128 √ó 128
            nn.Tanh()
        )

    def forward(self, z):
        h = self.fc(z)
        h = h.view(-1, 512, self.initial_dim, self.initial_dim)
        return self.net(h)


# ==============================
#   FULL VAE
# ==============================
class VAE(nn.Module):
    def __init__(self, img_size=128, latent_dim=256):
        super().__init__()
        self.enc = Encoder(in_channels=3, img_size=img_size, latent_dim=latent_dim)
        self.dec = Decoder(out_channels=3, img_size=img_size, latent_dim=latent_dim)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):
        mu, logvar = self.enc(x)
        z = self.reparameterize(mu, logvar)
        out = self.dec(z)
        return out, mu, logvar

from torchsummary import summary
vae = VAE(img_size=128, latent_dim=256).to(DEVICE)
summary(vae, (3, 128, 128))

"""Loss Functions"""

def vae_loss(recon_x, x, mu, logvar, recon_weight=1.0, kl_weight=1e-4):
    recon_loss = nn.functional.l1_loss(recon_x, x, reduction='mean')
    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()
    return recon_weight * recon_loss + kl_weight * kl, recon_loss.item(), kl.item()

def save_checkpoint(state, fpath):
    torch.save(state, fpath)

def load_checkpoint(fpath, model, optimizer=None):
    ck = torch.load(fpath, map_location=DEVICE)
    model.load_state_dict(ck['model_state'])
    if optimizer and 'optim_state' in ck:
        optimizer.load_state_dict(ck['optim_state'])
    return ck.get('epoch', 0), ck

"""Save Samples"""

def denorm(x):
    return x * 0.5 + 0.5

def sample_and_save(model, fixed_inputs, epoch, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    model.eval()
    with torch.no_grad():
        out,_,_ = model(fixed_inputs)
        combined = torch.cat([denorm(fixed_inputs.cpu()),
                              denorm(out.cpu())], dim=0)
        vutils.save_image(combined,
                          os.path.join(save_dir, f"epoch_{epoch:03}.png"),
                          nrow=fixed_inputs.size(0))
    model.train()

"""SSIM, PSNR, LPIPS, CLIP, FID"""

def compute_ssim_batch(img1, img2):
    # img tensors in [-1,1], shape (B,3,H,W)
    B = img1.shape[0]
    vals = []
    for i in range(B):
        a = ((img1[i].permute(1,2,0).cpu().numpy()*0.5)+0.5)*255
        b = ((img2[i].permute(1,2,0).cpu().numpy()*0.5)+0.5)*255
        a = a.astype(np.uint8); b = b.astype(np.uint8)
        try:
            s = ssim(a, b, multichannel=True, data_range=255)
        except:
            s = ssim(a[:,:,0], b[:,:,0], data_range=255)
        vals.append(s)
    return float(np.mean(vals))

def compute_psnr_batch(img1, img2):
    B = img1.shape[0]
    vals=[]
    for i in range(B):
        a = ((img1[i].permute(1,2,0).cpu().numpy()*0.5)+0.5)
        b = ((img2[i].permute(1,2,0).cpu().numpy()*0.5)+0.5)
        vals.append(psnr(a, b, data_range=1.0))
    return float(np.mean(vals))

def compute_lpips_batch(img1, img2):
    if not LPIPS_AVAILABLE: return None
    dev = next(lpips_alex.parameters()).device
    return float(lpips_alex(img1.to(dev), img2.to(dev)).mean().item())

def compute_clip_sim_batch(img1, img2):
    if not CLIP_AVAILABLE: return None
    imgs = torch.cat([img1, img2], dim=0)
    imgs = (imgs * 0.5) + 0.5  # [0,1]
    imgs = nn.functional.interpolate(imgs.to(DEVICE), size=(224,224), mode='bilinear', align_corners=False)
    mean = torch.tensor([0.48145466,0.4578275,0.40821073]).view(1,3,1,1).to(DEVICE)
    std  = torch.tensor([0.26862954,0.26130258,0.27577711]).view(1,3,1,1).to(DEVICE)
    imgs = (imgs - mean) / std
    with torch.no_grad():
        emb = clip_model.encode_image(imgs)
        emb = emb / emb.norm(dim=-1, keepdim=True)
    B = img1.shape[0]
    e1 = emb[:B]; e2 = emb[B:]
    sims = (e1 * e2).sum(dim=1).cpu().numpy()
    return float(sims.mean())

def compute_fid_cli(real_dir, fake_dir):
    try:
        out = subprocess.check_output(["pytorch-fid", real_dir, fake_dir])
        return out.decode('utf-8').strip()
    except Exception as e:
        return f"FID error: {e}"

from torch.cuda.amp import autocast, GradScaler

def train_vae(model, train_loader, val_loader, epochs=100, lr=1e-4,
              recon_weight=1.0, kl_weight=1e-4,
              save_dir=DRIVE_SAVE_DIR, resume_ckpt=None, save_every=1):
    os.makedirs(save_dir, exist_ok=True)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scaler = GradScaler()
    start_epoch = 1
    best_val_ssim = -1.0
    history = {'epoch':[], 'train_loss':[], 'val_ssim':[], 'val_psnr':[]}

    if resume_ckpt:
        start_epoch, _ = load_checkpoint(resume_ckpt, model, optimizer)
        start_epoch += 1
        print("Resuming from epoch", start_epoch)

    # fixed validation inputs for sample viewing (first batch)
    fixed_inputs = next(iter(val_loader))[0][:8].to(DEVICE)

    for epoch in range(start_epoch, epochs+1):
        model.train()
        running_loss = 0.0
        running_recon = 0.0
        running_kl = 0.0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{epochs}")
        for i, (sketches, real, _) in enumerate(pbar):
            sketches = sketches.to(DEVICE); real = real.to(DEVICE)
            optimizer.zero_grad()
            with autocast():
                recon, mu, logvar = model(sketches)
                loss, recon_loss_val, kl_val = vae_loss(recon, real, mu, logvar, recon_weight, kl_weight)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += float(loss.item())
            running_recon += recon_loss_val
            running_kl += kl_val
            pbar.set_postfix({"loss":running_loss/(i+1), "recon":running_recon/(i+1), "kl":running_kl/(i+1)})

        avg_loss = running_loss / len(train_loader)
        history['epoch'].append(epoch); history['train_loss'].append(avg_loss)

        # Save checkpoint (last)
        ckpt_path = os.path.join(save_dir, f"vae_epoch_{epoch:03d}.pth")
        save_checkpoint({'epoch':epoch, 'model_state': model.state_dict(), 'optim_state': optimizer.state_dict(), 'history':history}, ckpt_path)

        # Sample images
        sample_and_save(model, fixed_inputs, epoch, os.path.join(save_dir, "samples"))

        # Validation quick metrics on one batch (for speed)
        model.eval()
        with torch.no_grad():
            vsk, vreal, _ = next(iter(val_loader))
            vsk = vsk.to(DEVICE); vreal = vreal.to(DEVICE)
            vrecon, _, _ = model(vsk)
            val_ssim = compute_ssim_batch(vrecon.cpu(), vreal.cpu())
            val_psnr = compute_psnr_batch(vrecon.cpu(), vreal.cpu())
            history['val_ssim'].append(val_ssim); history['val_psnr'].append(val_psnr)
            print(f"Val (batch) SSIM: {val_ssim:.4f} PSNR: {val_psnr:.2f}")

        # Save best model by val_ssim
        if val_ssim > best_val_ssim:
            best_val_ssim = val_ssim
            best_path = os.path.join(save_dir, "best_vae.pth")
            save_checkpoint({'epoch':epoch, 'model_state': model.state_dict(), 'optim_state': optimizer.state_dict(), 'history':history}, best_path)
            print("Saved new best model:", best_path)

        # save history JSON
        with open(os.path.join(save_dir, "train_history.json"), "w") as f:
            json.dump(history, f)

    return model, history

latent_dim = 256
vae = VAE(img_size=IMG_SIZE, latent_dim=latent_dim).to(DEVICE)

resume_ckpt = None

model, history = train_vae(
    vae, train_loader, val_loader,
    epochs=100, lr=1e-4,
    recon_weight=1.0, kl_weight=1e-4,
    save_dir=DRIVE_SAVE_DIR,
    resume_ckpt=resume_ckpt
)

def find_latest_checkpoint(checkpoint_dir):
    import re, os
    files = os.listdir(checkpoint_dir)
    epoch_files = []
    pattern = re.compile(r"vae_epoch_(\d+)\.pth")
    for f in files:
        m = pattern.match(f)
        if m:
            epoch_files.append((int(m.group(1)), f))
    if not epoch_files:
        return None
    epoch_files.sort()
    return os.path.join(checkpoint_dir, epoch_files[-1][1])


checkpoint_dir = DRIVE_SAVE_DIR
latest_ckpt = find_latest_checkpoint(checkpoint_dir)

latent_dim = 256
vae = VAE(img_size=IMG_SIZE, latent_dim=latent_dim).to(DEVICE)

resume_ckpt = latest_ckpt if latest_ckpt else None

if resume_ckpt:
    print("‚úÖ Resuming from:", resume_ckpt)
else:
    print("‚úÖ Starting training from scratch.")

model, history = train_vae(
    vae,
    train_loader,
    val_loader,
    epochs=100,
    lr=1e-4,
    recon_weight=1.0,
    kl_weight=1e-4,
    save_dir=DRIVE_SAVE_DIR,
    resume_ckpt=resume_ckpt
)

import time

# Auto-save interval (seconds)
AUTOSAVE_INTERVAL = 300   # 5 minutes
last_autosave_time = time.time()

import os
import re

def find_latest_epoch_ckpt(checkpoint_dir):
    """
    Finds checkpoint like: vae_epoch_038.pth
    """
    files = os.listdir(checkpoint_dir)
    pattern = re.compile(r"vae_epoch_(\d+)\.pth")
    saved = []

    for f in files:
        m = pattern.match(f)
        if m:
            saved.append((int(m.group(1)), f))

    if not saved:
        return None

    saved.sort()
    return os.path.join(checkpoint_dir, saved[-1][1])



def find_resume_checkpoint(checkpoint_dir):
    autosave = os.path.join(checkpoint_dir, "autosave_latest.pth")
    if os.path.exists(autosave):
        print("‚úÖ Resuming from autosave checkpoint.")
        return autosave

    latest_epoch = find_latest_epoch_ckpt(checkpoint_dir)
    if latest_epoch:
        print("‚úÖ Resuming from:", latest_epoch)
        return latest_epoch

    print("‚úÖ No checkpoint found ‚Äî starting new training.")
    return None

def save_checkpoint(state, path):
    torch.save(state, path)

def load_checkpoint(path, model, optimizer=None):
    ck = torch.load(path, map_location=DEVICE)
    model.load_state_dict(ck['model_state'])
    if optimizer and "optim_state" in ck:
        optimizer.load_state_dict(ck["optim_state"])
    return ck.get("epoch", 0)

def train_vae(model, train_loader, val_loader, epochs, lr, recon_weight, kl_weight,
              save_dir, resume_ckpt=None):

    os.makedirs(save_dir, exist_ok=True)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scaler = GradScaler()

    start_epoch = 1

    # -----------------------------
    # ‚úÖ Load checkpoint if available
    # -----------------------------
    if resume_ckpt:
        loaded_epoch = load_checkpoint(resume_ckpt, model, optimizer)
        start_epoch = loaded_epoch + 1
        print(f"‚úÖ Resuming training from epoch {start_epoch}")

    global last_autosave_time

    # Fixed inputs for sample saving
    fixed_inputs = next(iter(val_loader))[0][:8].to(DEVICE)

    for epoch in range(start_epoch, epochs + 1):
        model.train()
        running_loss = 0.0
        running_recon = 0.0
        running_kl = 0.0

        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{epochs}")

        for i, (sketches, real, _) in enumerate(pbar):

            sketches = sketches.to(DEVICE)
            real = real.to(DEVICE)

            optimizer.zero_grad()

            with autocast(): # Changed from autocast("cuda")
                recon, mu, logvar = model(sketches)
                loss, recon_val, kl_val = vae_loss(recon, real, mu, logvar,
                                                   recon_weight, kl_weight)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()
            running_recon += recon_val
            running_kl += kl_val

            pbar.set_postfix({
                "loss": running_loss/(i+1),
                "recon": running_recon/(i+1),
                "kl": running_kl/(i+1),
            })

            # --------------------------------------
            # ‚úÖ AUTOSAVE CHECKPOINT EVERY 5 MINUTES
            # --------------------------------------
            if time.time() - last_autosave_time > AUTOSAVE_INTERVAL:
                autosave_path = os.path.join(save_dir, "autosave_latest.pth")
                save_checkpoint({
                    'epoch': epoch,
                    'model_state': model.state_dict(),
                    'optim_state': optimizer.state_dict(),
                }, autosave_path)
                print(f"\n‚úÖ Autosaved checkpoint at: {autosave_path}")
                last_autosave_time = time.time()

        # --------------------------------------
        # ‚úÖ SAVE NORMAL EPOCH CHECKPOINT
        # --------------------------------------
        epoch_ckpt = os.path.join(save_dir, f"vae_epoch_{epoch:03d}.pth")
        save_checkpoint({
            'epoch': epoch,
            'model_state': model.state_dict(),
            'optim_state': optimizer.state_dict(),
        }, epoch_ckpt)

        print(f"‚úÖ Saved epoch checkpoint: {epoch_ckpt}")

        # Save sample reconstruction image
        sample_and_save(model, fixed_inputs, epoch, os.path.join(save_dir, "samples"))

    return model

resume_ckpt = find_resume_checkpoint(DRIVE_SAVE_DIR)

vae = VAE(img_size=IMG_SIZE, latent_dim=256).to(DEVICE)

model = train_vae(
    vae,
    train_loader,
    val_loader,
    epochs=100,
    lr=1e-4,
    recon_weight=1.0,
    kl_weight=1e-4,
    save_dir=DRIVE_SAVE_DIR,
    resume_ckpt=resume_ckpt
)

!ls -lh "/content/drive/MyDrive/vae_sketch2real_checkpoints"

def find_resume_checkpoint(save_dir):
    autosave = os.path.join(save_dir, "autosave_latest.pth")
    if os.path.exists(autosave):
        print("‚úÖ Found autosave checkpoint. Will resume training.")
        return autosave
    else:
        print("‚ö†Ô∏è No autosave found. Training will start from epoch 1.")
        return None

from torch.amp import autocast, GradScaler

def train_vae(model, train_loader, val_loader, epochs, lr,
              recon_weight, kl_weight, save_dir, resume_ckpt=None):

    os.makedirs(save_dir, exist_ok=True)

    optimizer = optim.Adam(model.parameters(), lr=lr)
    scaler = GradScaler(device="cuda")

    start_epoch = 1

    # -------------------------------------------------------------
    # ‚úÖ Resume from checkpoint
    # -------------------------------------------------------------
    if resume_ckpt is not None and os.path.exists(resume_ckpt): # Added existence check
        print("‚úÖ Resuming from checkpoint:", resume_ckpt)
        try: # Added try-except block for robustness
            start_epoch, ckpt = load_checkpoint(resume_ckpt, model, optimizer)
            start_epoch += 1
            print(f"‚úÖ Resuming training from epoch {start_epoch}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load checkpoint {resume_ckpt}: {e}")
            print("‚ö†Ô∏è Starting training from epoch 1.")
            start_epoch = 1 # Reset to start from epoch 1 if loading fails


    best_val_ssim = -1
    history = {"epoch": [], "train_loss": []}

    # fixed val batch for images
    fixed_inputs = next(iter(val_loader))[0][:8].to(DEVICE)

    # -------------------------------------------------------------
    # ‚úÖ Training Loop
    # -------------------------------------------------------------
    for epoch in range(start_epoch, epochs + 1):

        model.train()
        running_loss = 0

        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{epochs}")

        for sketches, real, _ in pbar:
            sketches = sketches.to(DEVICE)
            real = real.to(DEVICE)

            optimizer.zero_grad()

            with autocast("cuda"):
                recon, mu, logvar = model(sketches)
                loss, rloss, kloss = vae_loss(
                    recon, real, mu, logvar,
                    recon_weight, kl_weight
                )

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()
            pbar.set_postfix({
                "loss": running_loss / (pbar.n or 1),
                "recon": rloss,
                "kl": kloss
            })

        # -------------------------------------------------------------
        # ‚úÖ Save epoch checkpoint
        # -------------------------------------------------------------
        epoch_ckpt = os.path.join(save_dir, f"vae_epoch_{epoch:03d}.pth")
        save_checkpoint({
            "epoch": epoch,
            "model_state": model.state_dict(),
            "optim_state": optimizer.state_dict()
        }, epoch_ckpt)
        print(f"‚úÖ Saved epoch checkpoint: {epoch_ckpt}")

        # -------------------------------------------------------------
        # ‚úÖ Auto-delete old checkpoints (keep only last 3)
        # -------------------------------------------------------------
        ckpts = sorted([f for f in os.listdir(save_dir) if f.startswith("vae_epoch_")])
        if len(ckpts) > 3:
            old = ckpts[:-3]
            for f in old:
                os.remove(os.path.join(save_dir, f))
                print(f"üóë Deleted old checkpoint: {f}")

        # -------------------------------------------------------------
        # ‚úÖ Save autosave checkpoint
        # -------------------------------------------------------------
        autosave_path = os.path.join(save_dir, "autosave_latest.pth")
        save_checkpoint({
            "epoch": epoch,
            "model_state": model.state_dict(),
            "optim_state": optimizer.state_dict()
        }, autosave_path)
        print(f"‚úÖ Autosaved checkpoint: {autosave_path}")

    return model

import os

ckpt_dir = "/content/drive/MyDrive/vae_sketch2real_checkpoints"

for f in os.listdir(ckpt_dir):
    if f.startswith("vae_epoch_"):
        epoch_num = int(f.split("_")[2].split(".")[0])
        if epoch_num < 43:   # keep only last 2‚Äì3 checkpoints
            os.remove(os.path.join(ckpt_dir, f))

print("‚úÖ Old checkpoints deleted safely.")

import os

autosave = "/content/drive/MyDrive/vae_sketch2real_checkpoints/autosave_latest.pth"
print("Exists:", os.path.exists(autosave))

def load_checkpoint(fpath, model, optimizer=None):
    ck = torch.load(fpath, map_location=DEVICE)
    model.load_state_dict(ck["model_state"])

    if optimizer is not None and "optim_state" in ck:
        optimizer.load_state_dict(ck["optim_state"])

    epoch = ck.get("epoch", 0)
    return epoch, ck       # ‚úÖ MUST return TWO values

from torch.amp import autocast, GradScaler

def train_vae(model, train_loader, val_loader, epochs, lr,
              recon_weight, kl_weight, save_dir, resume_ckpt=None):

    os.makedirs(save_dir, exist_ok=True)

    optimizer = optim.Adam(model.parameters(), lr=lr)
    scaler = GradScaler(device="cuda")

    start_epoch = 1

    # -------------------------------------------------------------
    # ‚úÖ Resume from checkpoint
    # -------------------------------------------------------------
    if resume_ckpt is not None and os.path.exists(resume_ckpt):
        print("‚úÖ Resuming from checkpoint:", resume_ckpt)
        try:
            start_epoch, ckpt = load_checkpoint(resume_ckpt, model, optimizer)
            start_epoch += 1
            print(f"‚úÖ Resuming training from epoch {start_epoch}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load checkpoint {resume_ckpt}: {e}")
            print("‚ö†Ô∏è Starting training from epoch 1.")
            start_epoch = 1

    best_val_ssim = -1
    history = {"epoch": [], "train_loss": []}

    fixed_inputs = next(iter(val_loader))[0][:8].to(DEVICE)

    # -------------------------------------------------------------
    # ‚úÖ Training Loop
    # -------------------------------------------------------------
    for epoch in range(start_epoch, epochs + 1):

        model.train()
        running_loss = 0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{epochs}")

        for sketches, real, _ in pbar:
            sketches = sketches.to(DEVICE)
            real = real.to(DEVICE)

            optimizer.zero_grad()

            # ‚úÖ Correct autocast syntax
            with autocast(device_type="cuda"):
                recon, mu, logvar = model(sketches)
                loss, rloss, kloss = vae_loss(
                    recon, real, mu, logvar,
                    recon_weight, kl_weight
                )

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()
            pbar.set_postfix({
                "loss": running_loss / (pbar.n or 1),
                "recon": rloss,
                "kl": kloss
            })

        # -------------------------------------------------------------
        # ‚úÖ Save epoch checkpoint
        # -------------------------------------------------------------
        epoch_ckpt = os.path.join(save_dir, f"vae_epoch_{epoch:03d}.pth")
        save_checkpoint({
            "epoch": epoch,
            "model_state": model.state_dict(),
            "optim_state": optimizer.state_dict()
        }, epoch_ckpt)
        print(f"‚úÖ Saved epoch checkpoint: {epoch_ckpt}")

        # -------------------------------------------------------------
        # ‚úÖ Auto-delete older checkpoints (keep only last 3)
        # -------------------------------------------------------------
        ckpts = sorted([f for f in os.listdir(save_dir) if f.startswith("vae_epoch_")])
        if len(ckpts) > 3:
            old = ckpts[:-3]
            for f in old:
                try:
                    os.remove(os.path.join(save_dir, f))
                    print(f"üóë Deleted old checkpoint: {f}")
                except:
                    pass

        # -------------------------------------------------------------
        # ‚úÖ Save autosave checkpoint
        # -------------------------------------------------------------
        autosave_path = os.path.join(save_dir, "autosave_latest.pth")
        save_checkpoint({
            "epoch": epoch,
            "model_state": model.state_dict(),
            "optim_state": optimizer.state_dict()
        }, autosave_path)
        print(f"‚úÖ Autosaved checkpoint: {autosave_path}")

    return model

resume_ckpt = "/content/drive/MyDrive/vae_sketch2real_checkpoints/vae_epoch_063.pth"

vae = VAE(img_size=IMG_SIZE, latent_dim=256).to(DEVICE)

model = train_vae(
    vae,
    train_loader,
    val_loader,
    epochs=100,
    lr=1e-4,
    recon_weight=1.0,
    kl_weight=1e-4,
    save_dir=DRIVE_SAVE_DIR,
    resume_ckpt=resume_ckpt
)

latent_dim = 256

def find_latest_ckpt(folder):
    autosave = os.path.join(folder, "autosave_latest.pth")
    if os.path.exists(autosave):
        print("‚úÖ Found autosave checkpoint:", autosave)
        return autosave

    epoch_files = sorted([f for f in os.listdir(folder) if f.startswith("vae_epoch_")])
    if epoch_files:
        latest_epoch_ckpt = os.path.join(folder, epoch_files[-1])
        if os.path.exists(latest_epoch_ckpt): # Added existence check
            print("‚úÖ Found latest epoch checkpoint:", latest_epoch_ckpt)
            return latest_epoch_ckpt
        else:
            print(f"‚ö†Ô∏è Latest epoch checkpoint found in list but not on disk: {latest_epoch_ckpt}")


    print("‚ö†Ô∏è No valid checkpoint found.") # Added message
    return None

resume_path = find_latest_ckpt(DRIVE_SAVE_DIR)
# The train_vae function will now use this resume_path and also check for existence.

# create directories
real_dir = os.path.join(DRIVE_SAVE_DIR, "fid_real")
fake_dir = os.path.join(DRIVE_SAVE_DIR, "fid_fake")
os.makedirs(real_dir, exist_ok=True); os.makedirs(fake_dir, exist_ok=True)

# Copy real validation targets (original files) into real_dir
for inp, tar in val_ds.pairs:
    dst = os.path.join(real_dir, os.path.basename(tar))
    if not os.path.exists(dst):
        shutil.copyfile(tar, dst)

# Generate fake images for all val set and save into fake_dir
vae.eval()
with torch.no_grad():
    for sketches, real, names in tqdm(val_loader, desc="Generating fake val images"):
        sketches = sketches.to(DEVICE)
        recons, _, _ = vae(sketches)
        recons = denorm(recons.cpu())
        for i, nm in enumerate(names):
            out_path = os.path.join(fake_dir, nm)
            vutils.save_image(recons[i], out_path)

# Compute FID via pytorch-fid CLI
fid_result = compute_fid_cli(real_dir, fake_dir)
print("FID result:", fid_result)

def eval_on_loader(model, loader):
    model.eval()
    ssim_list = []; psnr_list = []; lpips_list = []; clip_list = []
    with torch.no_grad():
        for sketches, real, _ in tqdm(loader, desc="Eval"):
            sketches = sketches.to(DEVICE); real = real.to(DEVICE)
            recons, _, _ = model(sketches)
            ssim_list.append(compute_ssim_batch(recons.cpu(), real.cpu()))
            psnr_list.append(compute_psnr_batch(recons.cpu(), real.cpu()))
            if LPIPS_AVAILABLE:
                lpips_list.append(compute_lpips_batch(recons, real))
            if CLIP_AVAILABLE:
                clip_list.append(compute_clip_sim_batch(recons, real))
    print("SSIM:", np.mean(ssim_list), "PSNR:", np.mean(psnr_list))
    if LPIPS_AVAILABLE: print("LPIPS:", np.mean(lpips_list))
    if CLIP_AVAILABLE: print("CLIP sim:", np.mean(clip_list))

# Evaluate on val and test
eval_on_loader(vae, val_loader)
eval_on_loader(vae, test_loader)

best_ckpt = os.path.join(DRIVE_SAVE_DIR, "best_vae.pth")
if os.path.exists(best_ckpt):
    load_epoch, _ = load_checkpoint(best_ckpt, vae)
    print("Loaded best ckpt from epoch", load_epoch)
else:
    print("Best checkpoint not found at", best_ckpt)

# pick a val sample and save generated image
sample_idx = 0
sketch, real, name = val_ds[sample_idx]
x = sketch.unsqueeze(0).to(DEVICE)
vae.eval()
with torch.no_grad():
    out, _, _ = vae(x)
out_img = denorm(out.cpu())[0]
out_path = os.path.join(DRIVE_SAVE_DIR, f"sample_out_{name}")
vutils.save_image(out_img, out_path)
print("Saved example output to:", out_path)

vae.eval()

samples = [val_ds[i] for i in range(4)]

sketch_batch = torch.stack([s[0] for s in samples]).to(DEVICE)
real_batch   = torch.stack([s[1] for s in samples]).to(DEVICE)

with torch.no_grad():
    gen_batch,_,_ = vae(sketch_batch)

# De-normalize
sketch_batch = denorm(sketch_batch.cpu())
real_batch   = denorm(real_batch.cpu())
gen_batch    = denorm(gen_batch.cpu())

rows = []
for i in range(4):
    row = torch.cat([sketch_batch[i], real_batch[i], gen_batch[i]], dim=2)
    rows.append(row)

final_grid = torch.cat(rows, dim=1)

#  SAVE to Drive
save_path = os.path.join(DRIVE_SAVE_DIR, "comparison_4_samples.png")
vutils.save_image(final_grid, save_path)
print(" Saved comparison image at:", save_path)

#  DISPLAY ON SCREEN (Colab)
plt.figure(figsize=(20, 8))
plt.imshow(final_grid.permute(1, 2, 0))   # CHW ‚Üí HWC
plt.axis("off")
plt.title("Sketch | Real | Generated (4 Samples)")
plt.show()

vae.eval()

samples = [val_ds[i] for i in range(4)]

sketch_batch = torch.stack([s[0] for s in samples]).to(DEVICE)
real_batch   = torch.stack([s[1] for s in samples]).to(DEVICE)

with torch.no_grad():
    gen_batch,_,_ = vae(sketch_batch)

sketch_batch = denorm(sketch_batch.cpu())
real_batch   = denorm(real_batch.cpu())
gen_batch    = denorm(gen_batch.cpu())

rows = []
for i in range(4):
    row = torch.cat([sketch_batch[i], real_batch[i], gen_batch[i]], dim=2)
    rows.append(row)

final_grid = torch.cat(rows, dim=1)

save_path = os.path.join(DRIVE_SAVE_DIR, "comparison_4_samples.png")
vutils.save_image(final_grid, save_path)

print(" Saved comparison image at:", save_path)

import torch

vae.eval()

sketch = denorm(sketch)
real = denorm(real)
generated = denorm(out.cpu()[0])

comparison = torch.cat([sketch, real, generated], dim=2)

comp_path = os.path.join(DRIVE_SAVE_DIR, "comparison_best_model.png")
vutils.save_image(comparison, comp_path)

print("‚úÖ Saved comparison image at:", comp_path)

def eval_on_loader(model, loader):
    model.eval()
    ssim_list = []; psnr_list = []; lpips_list = []; clip_list = []
    with torch.no_grad():
        for sketches, real, _ in tqdm(loader, desc="Eval"):
            sketches = sketches.to(DEVICE); real = real.to(DEVICE)
            recons, _, _ = model(sketches)

            ssim_list.append(compute_ssim_batch(recons.cpu(), real.cpu()))
            psnr_list.append(compute_psnr_batch(recons.cpu(), real.cpu()))

            if LPIPS_AVAILABLE:
                lpips_list.append(compute_lpips_batch(recons, real))
            if CLIP_AVAILABLE:
                clip_list.append(compute_clip_sim_batch(recons, real))

    return {
        "SSIM": float(np.mean(ssim_list)),
        "PSNR": float(np.mean(psnr_list)),
        "LPIPS": float(np.mean(lpips_list)) if LPIPS_AVAILABLE else None,
        "CLIP": float(np.mean(clip_list)) if CLIP_AVAILABLE else None
    }

val_metrics  = eval_on_loader(vae, val_loader)
test_metrics = eval_on_loader(vae, test_loader)

print("Validation Metrics:", val_metrics)
print("Test Metrics:", test_metrics)

import matplotlib.pyplot as plt
import numpy as np

# Prepare data
labels = ["SSIM", "PSNR"]
val_vals = [val_metrics["SSIM"], val_metrics["PSNR"]]
test_vals = [test_metrics["SSIM"], test_metrics["PSNR"]]

# Include LPIPS if available
if LPIPS_AVAILABLE:
    labels.append("LPIPS")
    val_vals.append(val_metrics["LPIPS"])
    test_vals.append(test_metrics["LPIPS"])

# Include CLIP if available
if CLIP_AVAILABLE:
    labels.append("CLIP")
    val_vals.append(val_metrics["CLIP"])
    test_vals.append(test_metrics["CLIP"])

x = np.arange(len(labels))
width = 0.35

plt.figure(figsize=(10, 6))
plt.bar(x - width/2, val_vals, width, label="Validation")
plt.bar(x + width/2, test_vals, width, label="Test")

plt.xticks(x, labels)
plt.title("Model Performance Metrics")
plt.ylabel("Score")
plt.legend()
plt.grid(axis="y", linestyle="--", alpha=0.6)

plt.show()

import pandas as pd

df = pd.DataFrame({
    "Metric": labels,
    "Validation": val_vals,
    "Test": test_vals
})

df